{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synth training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddsp import DDSP, AudioDataset, CLAPLoss\n",
    "from ddsp.callbacks import BetaWarmupCallback\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import lightning as L\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.set_default_device('cuda')\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Model parameters\n",
    "# model_name = 'liget'\n",
    "model_name = 'drums'\n",
    "fs = 44100\n",
    "n_signal = 1.5 * fs # 1.5 seconds\n",
    "training_path_root = '/home/btadeusz/code/ddsp_vae/training/seven-manifolds'\n",
    "models_path_root = '/home/btadeusz/code/ddsp_vae/models/seven-manifolds'\n",
    "# dataset_path = '/mnt/mariadata/datasets/seven_manifolds/liget'\n",
    "dataset_path = '/mnt/mariadata/datasets/seven_manifolds/drums'\n",
    "\n",
    "# DDSP parameters\n",
    "n_filters = 768\n",
    "n_sines = 0\n",
    "latent_size = 8\n",
    "\n",
    "# Training config\n",
    "warmup_start = 300\n",
    "warmup_end = 500\n",
    "beta = 0\n",
    "max_epochs = 500\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Training dir\n",
    "training_path = os.path.join(training_path_root, model_name)\n",
    "synth_output_path = os.path.join(models_path_root, f'{model_name}.ts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitiate the training path\n",
    "shutil.rmtree(training_path, ignore_errors=True)\n",
    "os.makedirs(training_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = AudioDataset(dataset_path=dataset_path, n_signal=n_signal, sampling_rate=fs)\n",
    "\n",
    "train_set, val_set = random_split(dataset, [0.9, 0.1], generator=torch.Generator(device='cuda'))\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=0, generator=torch.Generator(device='cuda'))\n",
    "val_loader = DataLoader(val_set, batch_size=16, shuffle=False, num_workers=0, generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialisation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "ddsp = DDSP(\n",
    "  n_filters=n_filters,\n",
    "  n_sines=n_sines,\n",
    "  fs=fs,\n",
    "  latent_size=latent_size,\n",
    "  learning_rate=learning_rate\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "## Callbacks\n",
    "training_callbacks = []\n",
    "\n",
    "beta_warmup = BetaWarmupCallback(\n",
    "  beta=beta,\n",
    "  start_steps=warmup_start,\n",
    "  end_steps=warmup_end\n",
    ")\n",
    "training_callbacks.append(beta_warmup)\n",
    "\n",
    "# last_checkpoint_callback = ModelCheckpoint(\n",
    "#     filename='last',\n",
    "#     save_top_k=1,  # Save only one file, the most recent one\n",
    "#     save_last=True  # Always save the model at the end of the epoch\n",
    "#   )\n",
    "# training_callbacks.append(last_checkpoint_callback)\n",
    "\n",
    "# best checkopint callback, given the validation loss\n",
    "best_checkpoint_callback = ModelCheckpoint(\n",
    "  filename='best',\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_top_k=1,  # Save only one file, the best one\n",
    ")\n",
    "training_callbacks.append(best_checkpoint_callback)\n",
    "\n",
    "## Trainer\n",
    "tb_logger = TensorBoardLogger(training_path_root, name=model_name)\n",
    "\n",
    "# from lightning.pytorch.profilers import PyTorchProfiler\n",
    "# profiler = PyTorchProfiler(with_stack=True)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "  callbacks=training_callbacks,\n",
    "  max_epochs=max_epochs,\n",
    "  accelerator='cuda',\n",
    "  precision=16,\n",
    "  log_every_n_steps=0,\n",
    "  logger=tb_logger,\n",
    "  # profiler=profiler\n",
    ")\n",
    "\n",
    "## Start training\n",
    "trainer.fit(\n",
    "  model=ddsp,\n",
    "  train_dataloaders=train_loader,\n",
    "  val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddsp = ddsp.cuda()\n",
    "from random import randint\n",
    "test_x = dataset[randint(0, len(dataset))].unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_y = ddsp(test_x)\n",
    "\n",
    "print(\"Input\")\n",
    "display(Audio(test_x.squeeze(0).cpu().numpy(), rate=fs))\n",
    "\n",
    "print(\"Output\")\n",
    "display(Audio(test_y.squeeze().cpu().numpy(), rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning with CLAP loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze parameters\n",
    "# ddsp = ddsp.cuda()\n",
    "# ddsp.train()\n",
    "# # ddsp.encoder.eval()\n",
    "# for param in ddsp.encoder.parameters():\n",
    "#   param.requires_grad = False\n",
    "\n",
    "# ddsp._recons_loss = CLAPLoss()\n",
    "\n",
    "# max_epochs = 100\n",
    "# trainer = L.Trainer(\n",
    "#   callbacks=training_callbacks,\n",
    "#   max_epochs=max_epochs,\n",
    "#   accelerator='cuda',\n",
    "#   precision=16,\n",
    "#   log_every_n_steps=0,\n",
    "#   logger=tb_logger,\n",
    "#   # profiler=profiler\n",
    "# )\n",
    "\n",
    "# trainer.fit(\n",
    "#   model=ddsp,\n",
    "#   train_dataloaders=train_loader,\n",
    "#   val_dataloaders=val_loader,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "!python -m cli.export --model_directory {training_path} --output_path  {synth_output_path} --type best\n",
    "\n",
    "print(f'Model saved at {synth_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_batch_size = 64\n",
    "d_model = 64 # model dimensionality\n",
    "sequence_length = 128\n",
    "nhead = 2\n",
    "num_layers = 6\n",
    "prior_epochs = 100\n",
    "dataset_stride_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddsp.prior import Prior, PriorDataset\n",
    "\n",
    "prior_model_name = f'{model_name}-prior'\n",
    "\n",
    "# Training dir\n",
    "prior_training_path = os.path.join(training_path_root, prior_model_name)\n",
    "\n",
    "# Reinitiate the training path\n",
    "shutil.rmtree(prior_training_path, ignore_errors=True)\n",
    "os.makedirs(prior_training_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior dataset\n",
    "The Prior dataset is the same as the audio dataset encoded by the synth encoder into the latent space and arranged into sequences, ready for the sequence prediction training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dataset = PriorDataset(\n",
    "  audio_dataset_path=dataset_path,\n",
    "  encoding_model_path=synth_output_path,\n",
    "  sequence_length=sequence_length+1,\n",
    "  sampling_rate=fs,\n",
    "  device='cuda',\n",
    "  stride_factor=dataset_stride_factor\n",
    ")\n",
    "\n",
    "generator = torch.Generator(device='cuda')\n",
    "prior_train_set, prior_val_set = random_split(prior_dataset, [0.8, 0.2], generator=generator)\n",
    "prior_train_loader = DataLoader(prior_train_set, batch_size=prior_batch_size, shuffle=True, generator=generator)\n",
    "prior_val_loader = DataLoader(prior_val_set, batch_size=prior_batch_size, shuffle=False, generator=generator)\n",
    "\n",
    "latent_size = prior_dataset[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialisation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Prior(\n",
    "  latent_size=latent_size,\n",
    "  d_model=d_model,\n",
    "  max_len=sequence_length,\n",
    "  lr=1e-3,\n",
    "  nhead=nhead,\n",
    "  num_layers=num_layers,\n",
    ")\n",
    "\n",
    "prior_logger = TensorBoardLogger(prior_training_path, name=prior_model_name)\n",
    "\n",
    "prior_callbacks = []\n",
    "prior_checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=prior_training_path,\n",
    "  filename='best',\n",
    "  monitor='val_loss',\n",
    "  mode='min'\n",
    ")\n",
    "prior_callbacks.append(prior_checkpoint_callback)\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1000, stopping_threshold=4e-3)\n",
    "prior_callbacks.append(early_stopping)\n",
    "\n",
    "prior_trainer = L.Trainer(\n",
    "  callbacks=prior_callbacks,\n",
    "  accelerator='cuda',\n",
    "  log_every_n_steps=4,\n",
    "  logger=prior_logger,\n",
    "  max_epochs=prior_epochs\n",
    ")\n",
    "\n",
    "# Start training\n",
    "prior_trainer.fit(\n",
    "  model=prior,\n",
    "  train_dataloaders=prior_train_loader,\n",
    "  val_dataloaders=prior_val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_val_loss = prior_trainer.callback_metrics['val_loss']\n",
    "print(f'Final validation loss: {prior_val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import jit\n",
    "synth = jit.load(synth_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Number of steps to generate\n",
    "num_steps = 15000\n",
    "\n",
    "prior = prior.train().to('cuda')\n",
    "\n",
    "# Initialize the sequence with the given random codes\n",
    "# sequence = torch.zeros(1, sequence_length, latent_size, device='cuda')\n",
    "\n",
    "sequence = prior_dataset[1000].unsqueeze(0).to('cuda')\n",
    "\n",
    "# Generate latent codes autoregressively\n",
    "for _ in range(num_steps):\n",
    "  # Predict the next latent code\n",
    "  with torch.no_grad():\n",
    "    next_code = prior(sequence[:, -sequence_length:, :])\n",
    "\n",
    "  # Append the predicted code to the sequence and shift the sequence to the right\n",
    "  sequence = torch.cat((sequence, next_code[:, -1:, :]), dim=1)\n",
    "\n",
    "mu, logvar = sequence.chunk(2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "  latents, _ = synth.pretrained.encoder.reparametrize(mu, logvar)\n",
    "  audio = synth.decode(latents.permute(0, 2, 1).to('cpu'))\n",
    "\n",
    "# display latents\n",
    "plt.plot(latents.squeeze(0).cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "# display audio\n",
    "audio = audio.cpu().numpy().squeeze()\n",
    "audio = audio / audio.max()\n",
    "audio_widget = Audio(audio, rate=fs)\n",
    "display(audio_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  display(Audio(dataset[2].cpu().numpy(), rate=fs))\n",
    "  display(Audio(synth.pretrained(dataset[2].unsqueeze(0).cpu()).squeeze().numpy(), rate=fs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
